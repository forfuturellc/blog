---
layout: post
#permalink: /posts/001/
permalink: /wip/3fbac913-3bd7-4135-9cdb-531362babcd2/
title: Pothole, an API rate-limit respecting approach
tags: [software architecture]
comments: false
author: GochoMugo
wip: true
---

> This post presents a rather simple approach to handle *less frequent,
> short bursts* of calls against a rate-limited API, for example,
> during application startup. Some compromising is intended to avoid
> having to require strict coordination of your application's
> components in using the API. It can be viewed as **throttling** with
> the added feature of **queuing functions** for invocation at a later
> time.


## Introduction

In some applications relying on a third-party API for data retrieval,
processing, etc., bursts of calls to the API may be experienced.
In particular, during the startup phase of the application, we may
require to fetch enormous amounts of data using multiple calls to the
same API. For example, ...

The simplicity of this approach however comes at a price. It can
successfully applied in certain use cases with some trade-offs to consider.


## Terminology

The rate-limiting parameters of the API are described here as follows:

*Given a rate-limit of 50 requests per second,*

* **window**: time intervals between resetting of number of allowable requests.
* **length of window**: time, usually in milliseconds, a window lasts. In the
  case above, the window's length is *1 second (1000 ms)*.
* **size of window**: number of requests allowed in a window. Here above,
  the size is *50 requests*.
* **request**: a call to an API. It does not necessarily require it be over
  the network or be against a RESTful API. API of any kind should suffice.
* **pothole**: a component that handles queueing and executing your functions
  as specified in the windows' parameters.


## Elaboration

For this approach to work seamlessly in an application, the following
conditions would need to be satisfied:

* **short window**: The window needs to be short enough to allow us to
  queue a request and wait for it to be completed in subsequent windows.
* **moderate number of requests in a burst**: Preferably, have a request
  be statisfied across 2-3 windows, in a worst-case scenario.


Initially, we have an empty **queue** managed by a **pothole**. We
define the size and length of the window for our API. Instead of executing
our API calls directly, we queue them up in the pothole.

Let's denote the number of remaining requests allowed as **X**. Executing
an API call (through the pothole) decrements **X** by one each time.
**X** is set to the size of the window at start.

1. While **X** is greater than 0 (zero) and the queue is empty, the pothole
   executes the functions immediately without requiring to queue them
1. (**X** is 0 (zero)) Queue up the functions
1. Once the current window expires,
   * **X** is reset to the size of the window
   * Queued-up functions are executed, in the order they were queued.
   * Should the length of the queue exceed the size of the window, at its
   start, the functions remaining in the queue, once **X** hits 0 in this
   window, will have to be executed in the next windows, in a similar
   fashion.


## Drawbacks

This approach can be difficult to use in such cases:

* **high-level user request**: this refers to request from users in front
  of your application. Such applications need to be completed timely.
  Passing them through a pothole may hurt user experience due to unexpected
  lags.
* **polling**: Functions doing polling should not be passed through
  pothole as the intervals will not be respected. Also, consider a case where
  two polling requests are queued up. Once conditions allow, the may both
  be executed in quick succession, having them use the same set of
  'last-read' parameters. This will make the second request mostly useless.
* **in-process functional**: This is generally a problem with the
  implementation of the Pothole strategy. In my implementation,
  as used below in the demonstration, works with one process only.
  It is possible to implement the strategy for use in distributed
  fashions, such as in microservices.


## Demonstration

I built a [Node.js][node] module, [pothole][pothole], to apply this approach
in some of our applications.

In this simple demonstration, we shall have a server rate-limiting requests
at 10 requests per 30 seconds. Our client, on start, will do several number
of requests against the above server, with an aim of going over the limit.

You can obtain the working code below, in the post's repo at
[https://github.com/forfuturellc-x/blog-post-001][post-repo].

The server:

{% highlight_git js git://github.com/forfuturellc-x/blog-post-001 server.js linenos %}

The server implements a very basic API rate-limiting scheme. It is very
naive and for demonstration purposes.

The client:

{% highlight_git js git://github.com/forfuturellc-x/blog-post-001 client.js linenos  %}

You can notice we are simply passing functions to the Pothole
multiplexer above. This allows us to do almost anything within.
We could be doing network requests, as above, or disk IO, etc.

Sample output:

{% highlight_git txt git://github.com/forfuturellc-x/blog-post-001 test/sample-output.txt %}

As you can notice after every 10 requests, there is an apparent
pause of ~30,000ms (30 seconds). This is attributed to Pothole
waiting for the next window before firing the queued requests.

Although the `for` loop executes in its entirety without ever pausing to
wait for a request to complete, the limit is never exceeded.


## Conclusion

The benefit of loose but effective coordination of usage of the
API allows simpler architecture of application components. We
generally do **not** have to worry of rate-limiting issues in
suitable use cases. Pothole for the win!


---

#### References

1. [Node.js][node]: https://nodejs.org
1. [pothole, npm package][pothole]: https://npmjs.com/package/pothole
1. [Github repository for this blog post][post-repo]: https://github.com/forfuturellc-x/blog-post-001


[node]:https://nodejs.org
[pothole]:https://npmjs.com/package/pothole
[post-repo]:https://github.com/forfuturellc-x/blog-post-001
