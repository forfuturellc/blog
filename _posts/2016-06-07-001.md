---
layout: post
#permalink: /posts/001/
permalink: /wip/3fbac913-3bd7-4135-9cdb-531362babcd2/
title: Pothole, an API rate-limit respecting approach
tags: [software architecture]
comments: false
author: GochoMugo
wip: true
---

> This post presents a rather simple approach to handle *less frequent,
> short bursts* of calls against a rate-limited API, for example,
> during application startup. Some compromising is intended to avoid
> having to require strict coordination of your application's
> components in using the API. It can be viewed as **throttling** with
> the added feature of **queuing functions** for invocation at a later
> time.


## Introduction

In some applications relying on a third-party API for data retrieval,
processing, etc., bursts of calls to the API may be experienced.
In particular, during the startup phase of the application, we may
require to fetch enormous amounts of data using multiple calls to the
same API. For example, ...

The simplicity of this approach however comes at a price. It can
successfully applied in certain use cases with some trade-offs to consider.


## Terminology

The rate-limiting parameters of the API are described here as follows:

*Given a rate-limit of 50 requests per second,*

* **window**: time intervals between resetting of number of allowable requests.
* **length of window**: time, usually in milliseconds, a window lasts. In the
  case above, the window's length is *1 second (1000 ms)*.
* **size of window**: number of requests allowed in a window. Here above,
  the size is *50 requests*.
* **request**: a call to an API. It does not necessarily require it be over
  the network or be against a RESTful API. API of any kind should suffice.
* **pothole**: a component that handles queueing and executing your functions
  as specified in the windows' parameters.


## Elaboration

For this approach to work seamlessly in an application, the following
conditions would need to be satisfied:

* **short window**: The window needs to be short enough to allow us to
  queue a request and wait for it to be completed in subsequent windows.
* **moderate number of requests in a burst**: Preferably, have a request
  be statisfied across 2-3 windows, in a worst-case scenario.


Initially, we have an empty **queue** managed by a **pothole**. We
define the size and length of the window for our API. Instead of executing
our API calls directly, we queue them up in the pothole.

Let's denote the number of remaining requests allowed as **X**. Executing
an API call (through the pothole) decrements **X** by one each time.
**X** is set to the size of the window at start.

1. While **X** is greater than 0 (zero) and the queue is empty, the pothole
   executes the functions immediately without requiring to queue them
1. (**X** is 0 (zero)) Queue up the functions
1. Once the current window expires,
   * **X** is reset to the size of the window
   * Queued-up functions are executed, in the order they were queued.
   * Should the length of the queue exceed the size of the window, at its
   start, the functions remaining in the queue, once **X** hits 0 in this
   window, will have to be executed in the next windows, in a similar
   fashion.


## Drawbacks

This approach can be difficult to use in such cases:

* **high-level user request**: this refers to request from users in front
  of your application. Such applications need to be completed timely.
  Passing them through a pothole may hurt user experience due to unexpected
  lags.
* **polling**: Functions doing polling should not be passed through
  pothole as the intervals will not be respected. Also, consider a case where
  two polling requests are queued up. Once conditions allow, the may both
  be executed in quick succession, having them use the same set of
  'last-read' parameters. This will make the second request mostly useless.


## Extras

I built a [Node.js][node] module, [pothole][pothole], to apply this approach
in some of our applications.


[node]:https://nodejs.org
[pothole]:https://npmjs.com/package/pothole
